#' @title Replace "NA" values
#' @description In the first step, percentages of NAs in rows (features) and
#' columns (samples) are calculated. Next, features with high
#' percentage of NAs are removed (by default, features having more than 70
#' percent). Next, columns (samples) having high percentage of NAs are removed),
#' 80% by default.
#' Remaining NA values are replaced by imputed values generated by “local least
#' squares (llsImpute)“. If the first round of missing values imputation failed
#' or resulted in negative values, an additional missing value imputation using
#' impute.knn will be performed (rows with more than 50 percent of missing
#' values will be imputed using the overall mean per sample).
#' @param data a dataframe of gene/abundance counts.
#' @param pct.NA.row a number defining maximal percentage of NA values present
#' in a feature (e.g. a percentage of samples having "NA" in a given gene).
#' Features (rows) with a higher percentage of NA values will be removed (70 by
#' default).
#' @param pct.NA.column a number defining maximal percentage of NA values
#' present in a sample (e.g. a percentage of genes having NA in one sample).
#' Samples (columns) with a higher percentage of NA values will be removed
#' (80 by default).
#' @export
#' @import impute
#' @import pcaMethods
#' @import SummarizedExperiment
#' @return Data frame with replaced "NA" values
#' @examples {
#' ReplaceNAs(data=campp2_brca_1_NAs, pct.NA.row=70, pct.NA.column=80)
#' }

ReplaceNAs <- function(SE,pct.NA.row=70,pct.NA.column=80) {

    na_row <- apply(assay(SE), 1, function(x) (sum(is.na(x))/ncol(assay(SE)))*100)
    cat(paste0(" The input data has between " , round(min(na_row), digits = 2), "% - ", round(max(na_row), digits = 2),"%", " missing (NA) values per row. Features (rows) with more than ",pct.NA.row,"% missing values will be removed. \n"))
    removeNA=NULL
    removeNA <- which(as.vector(na_row) > pct.NA.row)
    if(length(removeNA)>0){
        cat(paste0(length(removeNA),"lines will be removed because of a high percentage of NAs"))
        SE_subset_rows<-SE[-removeNA,]
    } else {
        print("All rows fill requirement on percentage of NAs")
        SE_subset_rows<-SE
    }

    na_col <- apply(assay(SE_subset_rows), 2, function(x) (sum(is.na(x))/nrow(assay(SE_subset_rows)))*100)
    cat(paste0(" The input data after row removal has between " , round(min(na_col), digits = 2), "% - ", round(max(na_col), digits = 2),"%", " missing (NA) values per column. Samples (columns) with more than ", pct.NA.column,"% missing values will be removed. \n N.B. Uncertainty increases with number of missing values! \n "))
    removeNA=NULL
    removeNA <- which(as.vector(na_col) > pct.NA.column)
    if(length(removeNA)>0){
        cat(paste0(length(removeNA)," columns will be removed because of a high percentage of NAs"))
        SE_subset_rows_columns<-SE_subset_rows[,-removeNA]

    } else {
        print("All columns fill requirement of maximum percentage of NAs in the rows and columns.")
        SE_subset_rows_columns<-SE_subset_rows
    }




    still.NA <- c(unique(as.vector(is.na(assay(SE_subset_rows_columns)))))
    if (TRUE %in% still.NA) {
        print("Dataset still contains NA values which will be replaced.")

        if (checkData(as.matrix(assay(SE_subset_rows_columns)))[1] == FALSE) {
            assay(SE_subset_rows_columns, withDimnames=FALSE) <- as.data.frame(lapply(assay(SE_subset_rows_columns), as.numeric))
        }

        data.lls=NULL
        do_knn=FALSE

        print("Running Missing value estimation using local least squares (llsImpute); k=10, correlation=spearman.")

        k_value<-10

        if (k_value >= ncol(assay(SE_subset_rows_columns))) {
            k_value <- ncol(assay(SE_subset_rows_columns)) - 1
            cat("The specified k value is too large. Adjusting k to:", k_value, "\n")
        }

        # Remove rows where all values are NA
        SE_subset_rows_columns_rows <- SE_subset_rows_columns[!apply(is.na(assay(SE_subset_rows_columns)), 1, all), ]

        file <- try(data.lls <- data.frame(completeObs(llsImpute(as.matrix(assay(SE_subset_rows_columns_rows)), k = k_value, correlation="spearman", allVariables=TRUE))), silent =TRUE)

        if (!is(class(file), "try-error")){
            hasNegB <- unique(as.vector(assay(SE_subset_rows_columns) < 0))
            hasNegA <- unique(as.vector(data.lls < 0))
            do_knn <- TRUE %in% hasNegA & FALSE %in% hasNegB
        } else {
            do_knn <- TRUE
        }

        if (do_knn==TRUE){
            print("The first round of missing values imputation failed or resulted in negative values. Running additional missing value imputation using impute.knn. Rows with more than 50% missing values will be imputed using the overall mean per sample.")
            imputed_values <- impute.knn(as.matrix(assay(SE_subset_rows_columns_rows)), rowmax = 0.5)   ##This might generate "Error: C stack usage  xxx is too close to the limit" (probably the problem of insufficient RAM)
            assay(SE_subset_rows_columns_rows, withDimnames=FALSE) <- data.frame(imputed_values$data)
        } else {
            print("Missing value estimation using local least squares finished successfully.")
            assay(SE_subset_rows_columns_rows, withDimnames=FALSE) <- data.lls
        }

        final_output<-SE_subset_rows_columns_rows
    }

    final_output<-SE_subset_rows_columns

    return(final_output)}


